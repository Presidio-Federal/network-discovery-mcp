name: "HAI Network Discovery"
description: "Runs full discovery pipeline using a locally deployed FastAPI environment and uploads artifacts."

on:
  workflow_dispatch:
    inputs:
      seed_host:
        description: "Seed device IP or hostname"
        required: true
        default: "192.168.100.1"
      username:
        description: "Device username"
        required: true
        default: "cisco"
      password:
        description: "Device password (use GitHub secrets for production)"
        required: false
        default: "cisco"
      ports:
        description: "Ports to scan (comma-separated)"
        required: false
        default: "22,443"
      poll_interval:
        description: "Polling interval in seconds"
        required: false
        default: "10"

env:
  BASE_URL: "http://localhost:8000"
  POLL_INTERVAL: ${{ github.event.inputs.poll_interval || '10' }}

jobs:
  discover-network:
    runs-on: ubuntu-latest
    outputs:
      job_id: ${{ steps.seed.outputs.job_id }}
      reachable_hosts: ${{ steps.scan.outputs.reachable_hosts }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y jq curl
      
      # Step 0 - Deploy environment
      - name: Deploy network discovery environment
        run: |
          echo "Starting network discovery services..."
          docker compose -f ./docker-compose.yml up -d
          
          # Wait for service to start
          echo "Waiting for service to start..."
          MAX_RETRIES=30
          RETRY_COUNT=0
          
          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            if curl -s ${{ env.BASE_URL }}/ > /dev/null; then
              echo "Service is up and running"
              break
            fi
            
            echo "Waiting for service to start (attempt $((RETRY_COUNT+1))/$MAX_RETRIES)..."
            sleep 2
            RETRY_COUNT=$((RETRY_COUNT+1))
          done
          
          if [ $RETRY_COUNT -eq $MAX_RETRIES ]; then
            echo "Service failed to start within the timeout period"
            docker compose logs
            docker compose down
            exit 1
          fi
      
      # Step 1 - Start Seeding
      - name: Start seeding process
        id: seed
        run: |
          echo "Starting seed process from ${{ github.event.inputs.seed_host }}..."
          
          # Get password from input or secret
          PASSWORD="${{ github.event.inputs.password }}"
          if [ -z "$PASSWORD" ]; then
            PASSWORD="${{ secrets.DEVICE_PASSWORD }}"
          fi
          
          # Start seeder
          JOB_ID=$(curl -s -X POST "${{ env.BASE_URL }}/v1/seed" \
            -H "Content-Type: application/json" \
            -d "{
              \"seed_host\": \"${{ github.event.inputs.seed_host }}\",
              \"credentials\": {
                \"username\": \"${{ github.event.inputs.username }}\",
                \"password\": \"$PASSWORD\"
              },
              \"methods\": [\"interfaces\",\"routing\",\"arp\",\"cdp\"]
            }" | jq -r '.job_id')
          
          echo "Job ID: $JOB_ID"
          echo "job_id=$JOB_ID" >> $GITHUB_OUTPUT
          
          # Poll for seeder completion
          echo "Waiting for seeder to complete..."
          until [[ "$(curl -s ${{ env.BASE_URL }}/v1/status/$JOB_ID | jq -r '.seeder.status')" == "completed" ]]; do
            echo "Seeder in progress..."
            sleep ${{ env.POLL_INTERVAL }}
          done
          echo "Seeder completed"
      
      # Step 2 - Run IP Scan
      - name: Run IP scan
        id: scan
        run: |
          JOB_ID="${{ steps.seed.outputs.job_id }}"
          
          # Process probe ports
          IFS=',' read -ra PORT_ARRAY <<< "${{ github.event.inputs.ports }}"
          PROBE_PORTS="["
          for port in "${PORT_ARRAY[@]}"; do
            if [ "$PROBE_PORTS" != "[" ]; then
              PROBE_PORTS="$PROBE_PORTS,"
            fi
            PROBE_PORTS="$PROBE_PORTS$port"
          done
          PROBE_PORTS="$PROBE_PORTS]"
          
          echo "Running IP scan with ports $PROBE_PORTS..."
          curl -s -X POST "${{ env.BASE_URL }}/v1/scan" \
            -H "Content-Type: application/json" \
            -d "{
              \"job_id\": \"$JOB_ID\",
              \"ports\": $PROBE_PORTS,
              \"concurrency\": 200
            }"
          
          # Poll for scanner completion
          echo "Waiting for scanner to complete..."
          until [[ "$(curl -s ${{ env.BASE_URL }}/v1/status/$JOB_ID | jq -r '.scanner.status')" == "completed" ]]; do
            echo "Scanner in progress..."
            sleep ${{ env.POLL_INTERVAL }}
          done
          echo "Scanner completed"
          
          # Create artifacts directory
          mkdir -p ./discovery-artifacts
          
          # Retrieve reachable hosts
          echo "Retrieving reachable hosts..."
          curl -s "${{ env.BASE_URL }}/v1/scan/$JOB_ID/reachable" | jq '.' > ./discovery-artifacts/reachable.json
          REACHABLE=$(jq -c '.hosts' ./discovery-artifacts/reachable.json)
          echo "reachable_hosts=$REACHABLE" >> $GITHUB_OUTPUT
          
          # Display summary
          echo "Scan results:"
          echo "Reachable hosts: $(jq '.hosts | length' ./discovery-artifacts/reachable.json)"
          
      # Step 3 - Fingerprint
      - name: Fingerprint devices
        id: fingerprint
        run: |
          JOB_ID="${{ steps.seed.outputs.job_id }}"
          
          echo "Starting fingerprinting..."
          curl -s -X POST "${{ env.BASE_URL }}/v1/fingerprint" \
            -H "Content-Type: application/json" \
            -d "{\"job_id\": \"$JOB_ID\"}"
          
          # Poll for fingerprinting completion
          echo "Waiting for fingerprinting to complete..."
          until [[ "$(curl -s ${{ env.BASE_URL }}/v1/status/$JOB_ID | jq -r '.fingerprinter.status')" == "completed" ]]; do
            echo "Fingerprinting in progress..."
            sleep ${{ env.POLL_INTERVAL }}
          done
          echo "Fingerprinting completed"
          
          # Save fingerprint results
          curl -s "${{ env.BASE_URL }}/v1/fingerprint/$JOB_ID" | jq '.' > ./discovery-artifacts/fingerprints.json
      
      # Step 4 - Collect Device State
      - name: Collect device configurations
        id: state
        run: |
          JOB_ID="${{ steps.seed.outputs.job_id }}"
          
          # Get password from input or secret
          PASSWORD="${{ github.event.inputs.password }}"
          if [ -z "$PASSWORD" ]; then
            PASSWORD="${{ secrets.DEVICE_PASSWORD }}"
          fi
          
          echo "Collecting device configurations..."
          curl -s -X POST "${{ env.BASE_URL }}/v1/state/collect" \
            -H "Content-Type: application/json" \
            -d "{
              \"job_id\": \"$JOB_ID\",
              \"credentials\": {
                \"username\": \"${{ github.event.inputs.username }}\",
                \"password\": \"$PASSWORD\"
              },
              \"concurrency\": 25
            }"
          
          # Poll for state collection completion
          echo "Waiting for state collection to complete..."
          until [[ "$(curl -s ${{ env.BASE_URL }}/v1/status/$JOB_ID | jq -r '.state_collector.status')" == "completed" ]]; do
            echo "State collection in progress..."
            sleep ${{ env.POLL_INTERVAL }}
          done
          echo "State collection completed"
      
      # Step 5 - Build and Load Batfish Snapshot
      - name: Process with Batfish
        id: batfish
        run: |
          JOB_ID="${{ steps.seed.outputs.job_id }}"
          
          echo "Building Batfish snapshot..."
          curl -s -X POST "${{ env.BASE_URL }}/v1/batfish/build" \
            -H "Content-Type: application/json" \
            -d "{\"job_id\": \"$JOB_ID\"}"
          
          echo "Loading Batfish snapshot..."
          curl -s -X POST "${{ env.BASE_URL }}/v1/batfish/load" \
            -H "Content-Type: application/json" \
            -d "{\"job_id\": \"$JOB_ID\"}"
          
          # Poll for Batfish loading completion
          echo "Waiting for Batfish snapshot loading to complete..."
          until [[ "$(curl -s ${{ env.BASE_URL }}/v1/status/$JOB_ID | jq -r '.batfish_loader.status')" == "loaded" ]]; do
            echo "Batfish loading in progress..."
            sleep ${{ env.POLL_INTERVAL }}
          done
          echo "Batfish snapshot loaded"
          
          # Step 6 - Retrieve Topology
          echo "Retrieving network topology..."
          curl -s "${{ env.BASE_URL }}/v1/batfish/topology?job_id=$JOB_ID" -o ./discovery-artifacts/topology.json
          curl -s "${{ env.BASE_URL }}/v1/batfish/topology/html?job_id=$JOB_ID" -o ./discovery-artifacts/topology.html
          
          echo "Network topology saved to discovery-artifacts/topology.json and discovery-artifacts/topology.html"
      
      # Step 7 - Upload Artifacts
      - name: Upload discovery artifacts
        uses: actions/upload-artifact@v4
        with:
          name: network-discovery-results
          path: |
            ./discovery-artifacts/reachable.json
            ./discovery-artifacts/fingerprints.json
            ./discovery-artifacts/topology.json
            ./discovery-artifacts/topology.html
          retention-days: 7
      
      # Cleanup
      - name: Cleanup
        if: always()
        run: |
          echo "Cleaning up containers..."
          docker compose down
          echo "Cleanup complete"